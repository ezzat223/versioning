# =============================================================================
# MLOps CI/CD Pipeline - OPTIMIZED WITH AUTO-MERGE
# =============================================================================

variables:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://mlflow:5000"
  DOCKER_IMAGE_NAME: "{{ project_name }}-service"
  MODEL_NAME: "{{ project_name }}-model"
  EXPERIMENT_NAME: "{{ project_name }}-exp"
  DVC_REMOTE_NAME: "aws-store"
  DVC_S3_BUCKET: ""
  AWS_ENDPOINT_URL: ""

  # Conda optimization - use shared location, don't cache
  CONDA_PKGS_DIRS: "/opt/conda/pkgs"
  CONDA_ENV_NAME: "{{ project_name }}"
  MAMBA_NO_BANNER: "1"

  # Project-specific (customize these)
  DATA_PATH: "data/processed/dataset.csv"
  TARGET_COLUMN: "target"
  {% if task_type == 'supervised' %}
  PRIMARY_METRIC: "test_accuracy"
  {% elif task_type == 'unsupervised' %}
  PRIMARY_METRIC: "test_reconstruction_error"
  {% else %}
  PRIMARY_METRIC: "test_accuracy"
  {% endif %}

stages:
  - quality
  - validate
  - train
  - evaluate
  - deploy

# =============================================================================
# OPTIMIZED CACHE - Only cache pip and small artifacts
# =============================================================================
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - .cache/pip
    - .venv/
  policy: pull-push

# =============================================================================
# REUSABLE BLOCKS - DRY principle
# =============================================================================

.conda_setup: &conda_setup
  before_script:
    - echo "ğŸ”§ Setting up Conda environment..."
    - apt-get update -qq && apt-get install -y -qq build-essential gcc curl
    - conda config --set always_yes yes --set changeps1 no
    - conda config --add channels conda-forge
    - conda config --set channel_priority strict
    # Install mamba if not present
    - conda install -n base -c conda-forge mamba -y -q 2>/dev/null || true
    # Create/update environment directly (no caching overhead)
    - |
      if conda env list | grep -q "^${CONDA_ENV_NAME} "; then
        echo "ğŸ“¦ Updating existing conda environment..."
        mamba env update -n ${CONDA_ENV_NAME} -f environment.yml --prune -q
      else
        echo "ğŸ“¦ Creating new conda environment..."
        mamba env create -f environment.yml -q
      fi
    - source /opt/conda/etc/profile.d/conda.sh
    - conda activate ${CONDA_ENV_NAME}
    - echo "âœ… Conda environment ready"
    - |
      echo "Python location: $(which python)"
    - |
      echo "Python version: $(python --version)"

.dvc_setup: &dvc_setup
  - |
    if [ -n "$DVC_S3_BUCKET" ]; then
      echo "ğŸ”§ Configuring DVC remote..."
      dvc remote add -f ${DVC_REMOTE_NAME} s3://$DVC_S3_BUCKET
      [ -n "$AWS_ACCESS_KEY_ID" ] && dvc remote modify ${DVC_REMOTE_NAME} access_key_id $AWS_ACCESS_KEY_ID
      [ -n "$AWS_SECRET_ACCESS_KEY" ] && dvc remote modify ${DVC_REMOTE_NAME} secret_access_key $AWS_SECRET_ACCESS_KEY
      [ -n "$AWS_DEFAULT_REGION" ] && dvc remote modify ${DVC_REMOTE_NAME} region $AWS_DEFAULT_REGION
      [ -n "$AWS_ENDPOINT_URL" ] && dvc remote modify ${DVC_REMOTE_NAME} endpointurl $AWS_ENDPOINT_URL
      dvc remote default ${DVC_REMOTE_NAME}
    fi

# =============================================================================
# STAGE 1: CODE QUALITY (Lightweight - no conda needed)
# =============================================================================

code_quality:
  stage: quality
  image: python:${PYTHON_VERSION}-slim
  cache:
    key: quality-${CI_COMMIT_REF_SLUG}
    paths:
      - .cache/pip
    policy: pull-push
  before_script:
    - pip install --cache-dir .cache/pip black flake8 bandit safety
  script:
    - echo "ğŸ¨ Checking code formatting..."
    - |
      black --check src/ scripts/ || (echo "âŒ Run: black src/ scripts/" && exit 1)

    - echo "ğŸ” Linting code..."
    - flake8 src/ scripts/ --max-line-length=100 --ignore=E203,E402,E501,W503 || true

    - echo "ğŸ”’ Security scan..."
    - bandit -r src/ scripts/ -ll || true
    - safety scan || true

    - echo "âœ… Code quality checks complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 2: DATA VALIDATION
# =============================================================================

data_validation:
  stage: validate
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "ğŸ“Š Validating data quality..."
    - *dvc_setup
    - dvc pull -r ${DVC_REMOTE_NAME} || dvc pull || echo "âš ï¸ DVC pull failed (ensure remote configured)"

    - |
      python scripts/validate_data.py \
        --data ${DATA_PATH} \
        --suite iris_suite \
        --columns "sepal length (cm),sepal width (cm),petal length (cm),petal width (cm),species" \
        --column-types "sepal length (cm):float64,sepal width (cm):float64,petal length (cm):float64,petal width (cm):float64,species:int64"

    - echo "âœ… Data validation complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 3: TRAIN CHALLENGER MODEL
# =============================================================================

train_challenger:
  stage: train
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "ğŸš€ Training challenger model..."
    - *dvc_setup
    - dvc pull -r ${DVC_REMOTE_NAME} || dvc pull || echo "âš ï¸ DVC pull failed"

    # Train using DVC pipeline
    - dvc repro

    # Tag as challenger in MLflow
    - python scripts/tag_challenger.py --experiment-name ${EXPERIMENT_NAME}

    - echo "âœ… Challenger model trained and tagged"
  artifacts:
    paths:
      - metrics.json
      - models/
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 4: EVALUATE & COMPARE MODELS
# =============================================================================

evaluate_models:
  stage: evaluate
  image: continuumio/miniconda3:latest
  needs: ["train_challenger"]
  <<: *conda_setup
  script:
    - echo "ğŸ“Š Comparing challenger vs champion..."

    # Compare models and generate decision
    - |
      python scripts/compare_models.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --metric ${PRIMARY_METRIC} \
        --improvement-threshold 0.01 \
        --output comparison.json

    # Generate CML report
    - |
      python scripts/generate_cml_report.py \
        --comparison comparison.json \
        --output report.md

    # Post report to MR if in MR context
    - |
      if [ -n "$CI_MERGE_REQUEST_IID" ]; then
        echo "ğŸ“ Posting report to merge request..."

        # Install Node.js for CML
        curl -fsSL https://deb.nodesource.com/setup_20.x | bash -
        apt-get install -y nodejs

        # Install CML (the correct Node.js version)
        npm install -g @dvcorg/cml

        # Post comment to MR
        cml comment create report.md --target=pr || {
          echo "âš ï¸ CML comment failed, displaying report locally:"
          cat report.md
        }
      else
        echo "â„¹ï¸ Not in MR context, displaying report:"
        cat report.md
      fi

    # Extract promotion decision for next jobs
    - |
      PROMOTE=$(python -c "
      import json
      with open('comparison.json') as f:
          data = json.load(f)
      print('yes' if data.get('promote_challenger', False) else 'no')
      ")
      echo "PROMOTE_MODEL=${PROMOTE}" >> promote.env

      echo "================================================"
      if [ "$PROMOTE" == "yes" ]; then
        echo "âœ… DECISION: Will promote challenger to champion"
      else
        echo "âš ï¸ DECISION: Keeping current champion"
      fi
      echo "================================================"
  artifacts:
    paths:
      - comparison.json
      - report.md
    reports:
      dotenv: promote.env
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# MERGE DECISION GATE - Auto-merge control
# =============================================================================

merge_decision:
  stage: evaluate
  image: alpine:latest
  needs: ["evaluate_models"]
  script:
    - echo "ğŸ” Evaluating merge eligibility..."
    - echo ""
    - |
      if [ "$PROMOTE_MODEL" == "yes" ]; then
        echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
        echo "â”‚  âœ… MODEL QUALITY GATE: PASSED              â”‚"
        echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
        echo "â”‚  â†’ Challenger outperforms champion          â”‚"
        echo "â”‚  â†’ Improvement threshold met                â”‚"
        echo "â”‚  â†’ Pipeline will succeed                    â”‚"
        echo "â”‚  â†’ Merge approved for auto-merge            â”‚"
        echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
        echo ""
        exit 0
      else
        echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
        echo "â”‚  âŒ MODEL QUALITY GATE: FAILED              â”‚"
        echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
        echo "â”‚  â†’ Challenger does not improve champion     â”‚"
        echo "â”‚  â†’ Improvement threshold not met            â”‚"
        echo "â”‚  â†’ Pipeline will fail                       â”‚"
        echo "â”‚  â†’ BLOCKING merge to protect quality        â”‚"
        echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
        echo ""
        echo "â„¹ï¸  Review comparison.json and report.md for details"
        exit 1
      fi
  allow_failure: false
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

# =============================================================================
# STAGE 5: PROMOTE MODEL (Only if approved)
# =============================================================================

promote_model:
  stage: evaluate
  image: continuumio/miniconda3:latest
  needs: ["evaluate_models", "merge_decision"]
  <<: *conda_setup
  script:
    - echo "ğŸ† Promoting challenger to champion..."
    - python scripts/promote_model.py --experiment-name ${EXPERIMENT_NAME}
    - echo "âœ… Model promoted successfully"
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 6: DEPLOY TO PRODUCTION
# =============================================================================

{% if deployment in ['ray-serve', 'all'] %}
build_docker:
  stage: deploy
  image: docker:24
  services:
    - docker:24-dind
  needs: ["promote_model"]
  before_script:
    - echo "ğŸ” Logging into Docker registry..."
    - docker login -u $DOCKER_HUB_USERNAME -p $DOCKER_HUB_TOKEN
  script:
    - echo "ğŸ³ Building deployment image..."
    - |
      docker build \
        -f deployment/Dockerfile.ray \
        -t ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        -t ${DOCKER_IMAGE_NAME}:latest \
        --build-arg MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \
        --build-arg MODEL_NAME=${MODEL_NAME} \
        .

    - echo "ğŸ“¤ Pushing images to registry..."
    - docker push ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${DOCKER_IMAGE_NAME}:latest

    - echo "âœ… Docker images published"
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'

deploy_ray_serve:
  stage: deploy
  image: continuumio/miniconda3:latest
  needs: ["build_docker"]
  <<: *conda_setup
  script:
    - echo "ğŸš€ Deploying to Ray Serve..."
    - |
      python deployment/deploy_ray.py \
        --image ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        --replicas 2 \
        --environment production
    - echo "âœ… Deployment complete"
  environment:
    name: production
    url: http://ray-serve.example.com
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'
{% endif %}

# =============================================================================
# MANUAL OPERATIONS
# =============================================================================

rollback_model:
  stage: deploy
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "âª Rolling back to previous champion..."
    - python scripts/rollback_model.py --experiment-name ${EXPERIMENT_NAME}
    - echo "âœ… Rollback complete"
  when: manual
  only:
    - main

sync_data_remote:
  stage: deploy
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "â˜ï¸ Syncing data to remote storage..."
    - *dvc_setup
    - dvc push -r ${DVC_REMOTE_NAME} || echo "âš ï¸ Configure AWS credentials"
    - echo "âœ… Data sync complete"
  when: manual
  only:
    - main

# =============================================================================
# EMERGENCY: Force merge (use with caution)
# =============================================================================

force_promote:
  stage: deploy
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "âš ï¸ FORCE PROMOTING MODEL (bypassing quality gate)"
    - python scripts/promote_model.py --experiment-name ${EXPERIMENT_NAME} --force
    - echo "âœ… Force promotion complete"
  when: manual
  only:
    - main
  allow_failure: false
