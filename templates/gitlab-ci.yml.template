# =============================================================================
# MLOps CI/CD Pipeline - SIMPLIFIED & EFFECTIVE
# =============================================================================

variables:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://mlflow:5000"
  DOCKER_IMAGE_NAME: "{{ project_name }}-service"
  MODEL_NAME: "{{ project_name }}-model"
  EXPERIMENT_NAME: "{{ project_name }}-exp"

  # Project-specific (customize these)
  DATA_PATH: "data/processed/dataset.csv"
  TARGET_COLUMN: "target"
  PRIMARY_METRIC: "test_accuracy"

stages:
  - quality
  - validate
  - train
  - evaluate
  - deploy

# Cache for faster builds
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - .cache/pip
    - .venv/

# =============================================================================
# STAGE 1: CODE QUALITY (Keep it simple!)
# =============================================================================

code_quality:
  stage: quality
  image: python:${PYTHON_VERSION}-slim
  before_script:
    - pip install black flake8 bandit safety
  script:
    # Formatting
    - echo "üé® Checking code formatting..."
    - |
      black --check src/ scripts/ || (echo "Run: black src/ scripts/" && exit 1)

    # Linting
    - echo "üîç Linting..."
    - flake8 src/ scripts/ --max-line-length=100 --ignore=E203,W503 || true

    # Security (just the essentials)
    - echo "üîí Security scan..."
    - bandit -r src/ scripts/ -ll || true
    - safety check || true

    - echo "‚úÖ Code quality checks complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 2: DATA VALIDATION
# =============================================================================

data_validation:
  stage: validate
  image: continuumio/miniconda3:latest
  before_script:
    - conda env create -f environment.yml || conda env update -f environment.yml
  script:
    - echo "üìä Validating data quality..."
    - conda run -n {{ project_name }} dvc pull || echo "‚ö†Ô∏è DVC pull failed"

    # Single validation script with Great Expectations
    - conda run -n {{ project_name }} python scripts/validate_data.py --data ${DATA_PATH}

    - echo "‚úÖ Validation complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 3: TRAIN CHALLENGER
# =============================================================================

train_challenger:
  stage: train
  image: continuumio/miniconda3:latest
  services:
    - name: mlflow/mlflow:latest
      alias: mlflow
  before_script:
    - conda env create -f environment.yml || conda env update -f environment.yml
  script:
    - echo "üöÄ Training challenger model..."
    - conda run -n {{ project_name }} dvc pull

    # Train using DVC pipeline
    - conda run -n {{ project_name }} dvc repro

    # Tag as challenger
    - conda run -n {{ project_name }} python scripts/tag_challenger.py --experiment-name ${EXPERIMENT_NAME}

    - echo "‚úÖ Challenger trained"
  artifacts:
    paths:
      - metrics.json
      - mlruns/
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 4: COMPARE & DECIDE (with CML)
# =============================================================================

evaluate_models:
  stage: evaluate
  image: iterativeai/cml:0-dvc2-base1  # Official CML image
  needs: ["train_challenger"]
  before_script:
    - conda env create -f environment.yml || conda env update -f environment.yml
  script:
    - echo "üìä Comparing models..."

    # Compare challenger vs champion
    - |
      conda run -n {{ project_name }} python scripts/compare_models.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --metric ${PRIMARY_METRIC} \
        --improvement-threshold 0.01 \
        --output comparison.json

    # Generate markdown report using Python
    - |
      conda run -n {{ project_name }} python scripts/generate_cml_report.py \
        --comparison comparison.json \
        --output report.md

    # Post report to MR using CML
    - |
      if [ "$CI_MERGE_REQUEST_IID" != "" ]; then
        cml comment create report.md
      else
        echo "Not in MR context, skipping CML comment"
        cat report.md
      fi

    # Decide on promotion
    - |
      PROMOTE=$(conda run -n {{ project_name }} python -c "
      import json
      with open('comparison.json') as f:
          data = json.load(f)
      print('yes' if data.get('promote_challenger', False) else 'no')
      ")
      echo "PROMOTE_MODEL=${PROMOTE}" >> promote.env

      if [ "$PROMOTE" == "yes" ]; then
        echo "‚úÖ Will promote challenger"
      else
        echo "‚ö†Ô∏è Keeping current champion"
      fi
  artifacts:
    paths:
      - comparison.json
      - report.md
    reports:
      dotenv: promote.env
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 5: PROMOTE (Only if better)
# =============================================================================

promote_model:
  stage: evaluate
  image: continuumio/miniconda3:latest
  needs: ["evaluate_models"]
  before_script:
    - conda env create -f environment.yml || conda env update -f environment.yml
  script:
    - echo "üèÜ Promoting challenger to champion..."
    - conda run -n {{ project_name }} python scripts/promote_model.py --experiment-name ${EXPERIMENT_NAME}
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 6: DEPLOY (Only on main with promotion)
# =============================================================================

{% if deployment in ['ray-serve', 'all'] %}
build_docker:
  stage: deploy
  image: docker:24
  services:
    - docker:24-dind
  needs: ["promote_model"]
  script:
    - echo "üê≥ Building deployment image..."
    - docker login -u $DOCKER_HUB_USERNAME -p $DOCKER_HUB_TOKEN

    - |
      docker build \
        -f deployment/Dockerfile.ray \
        -t ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        -t ${DOCKER_IMAGE_NAME}:latest \
        .

    - docker push ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${DOCKER_IMAGE_NAME}:latest

    - echo "‚úÖ Image pushed"
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'
{% endif %}

# =============================================================================
# MANUAL JOBS
# =============================================================================

rollback_model:
  stage: deploy
  image: continuumio/miniconda3:latest
  before_script:
    - conda env create -f environment.yml || conda env update -f environment.yml
  script:
    - echo "‚è™ Rolling back to previous champion..."
    - conda run -n {{ project_name }} python scripts/rollback_model.py --experiment-name ${EXPERIMENT_NAME}
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# Push data to remote (manual for cost control)
sync_data_remote:
  stage: deploy
  image: continuumio/miniconda3:latest
  before_script:
    - conda env create -f environment.yml || conda env update -f environment.yml
  script:
    - echo "‚òÅÔ∏è Syncing data to remote storage..."
    - conda run -n {{ project_name }} dvc push -r aws-store || echo "Configure AWS credentials first"
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
