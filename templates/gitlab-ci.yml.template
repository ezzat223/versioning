# =============================================================================
# MLOps CI/CD Pipeline - FULLY AUTOMATED WITH QUALITY GATES
# =============================================================================
#
# WORKFLOW:
# 1. MR Pipeline: quality â†’ validate â†’ train â†’ evaluate â†’ promote â†’ auto-merge
# 2. Main Pipeline: Only runs deployment jobs (no re-training/evaluation)
#
# REQUIREMENTS:
# - Set GITLAB_API_TOKEN in CI/CD variables (Project Settings > CI/CD > Variables)
#   Scope: api, write_repository | Create at: User Settings > Access Tokens
#
# =============================================================================

variables:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://mlflow:5000"
  DOCKER_IMAGE_NAME: "{{ project_name }}-service"
  MODEL_NAME: "{{ project_name }}-model"
  EXPERIMENT_NAME: "{{ project_name }}-exp"
  DVC_REMOTE_NAME: "aws-store"
  DVC_S3_BUCKET: ""
  AWS_ENDPOINT_URL: ""

  # Conda optimization - use shared location, don't cache
  CONDA_PKGS_DIRS: "/opt/conda/pkgs"
  CONDA_ENV_NAME: "{{ project_name }}"
  MAMBA_NO_BANNER: "1"

  # Project-specific (customize these)
  DATA_PATH: "data/processed/dataset.csv"
  TARGET_COLUMN: "target"
  {% if task_type == 'supervised' %}
  PRIMARY_METRIC: "test_accuracy"
  {% elif task_type == 'unsupervised' %}
  PRIMARY_METRIC: "test_reconstruction_error"
  {% else %}
  PRIMARY_METRIC: "test_accuracy"
  {% endif %}

stages:
  - quality
  - validate
  - train
  - evaluate
  - deploy

# =============================================================================
# OPTIMIZED CACHE - Only cache pip and small artifacts
# =============================================================================
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - .cache/pip
    - .venv/
  policy: pull-push

# =============================================================================
# REUSABLE BLOCKS - DRY principle
# =============================================================================

.conda_setup: &conda_setup
  before_script:
    - echo "ğŸ”§ Setting up Conda environment..."
    - apt-get update -qq && apt-get install -y -qq build-essential gcc curl
    - conda config --set always_yes yes --set changeps1 no
    - conda config --add channels conda-forge
    - conda config --set channel_priority strict
    # Install mamba if not present
    - conda install -n base -c conda-forge mamba -y -q 2>/dev/null || true
    # Create/update environment directly (no caching overhead)
    - |
      if conda env list | grep -q "^${CONDA_ENV_NAME} "; then
        echo "ğŸ“¦ Updating existing conda environment..."
        mamba env update -n ${CONDA_ENV_NAME} -f environment.yml --prune -q
      else
        echo "ğŸ“¦ Creating new conda environment..."
        mamba env create -f environment.yml -q
      fi
    - source /opt/conda/etc/profile.d/conda.sh
    - conda activate ${CONDA_ENV_NAME}
    - echo "âœ… Conda environment ready"
    - |
      echo "Python location: $(which python)"
    - |
      echo "Python version: $(python --version)"

.dvc_setup: &dvc_setup
  - |
    if [ -n "$DVC_S3_BUCKET" ]; then
      echo "ğŸ”§ Configuring DVC remote..."
      dvc remote add -f ${DVC_REMOTE_NAME} s3://$DVC_S3_BUCKET
      [ -n "$AWS_ACCESS_KEY_ID" ] && dvc remote modify ${DVC_REMOTE_NAME} access_key_id $AWS_ACCESS_KEY_ID
      [ -n "$AWS_SECRET_ACCESS_KEY" ] && dvc remote modify ${DVC_REMOTE_NAME} secret_access_key $AWS_SECRET_ACCESS_KEY
      [ -n "$AWS_DEFAULT_REGION" ] && dvc remote modify ${DVC_REMOTE_NAME} region $AWS_DEFAULT_REGION
      [ -n "$AWS_ENDPOINT_URL" ] && dvc remote modify ${DVC_REMOTE_NAME} endpointurl $AWS_ENDPOINT_URL
      dvc remote default ${DVC_REMOTE_NAME}
    fi

# =============================================================================
# STAGE 1: CODE QUALITY (Lightweight - no conda needed)
# =============================================================================

code_quality:
  stage: quality
  image: python:${PYTHON_VERSION}-slim
  cache:
    key: quality-${CI_COMMIT_REF_SLUG}
    paths:
      - .cache/pip
    policy: pull-push
  before_script:
    - pip install --cache-dir .cache/pip black flake8 bandit safety
  script:
    - echo "ğŸ¨ Checking code formatting..."
    - |
      black --check src/ scripts/ training/ || (echo "âŒ Run: black src/ scripts/ training/" && exit 1)

    - echo "ğŸ” Linting code..."
    - flake8 src/ scripts/ training/ --max-line-length=100 --ignore=E203,E402,E501,W503 || true

    - echo "ğŸ”’ Security scan..."
    - bandit -r src/ scripts/ -ll || true
    - safety scan || true

    - echo "âœ… Code quality checks complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

# =============================================================================
# STAGE 2: DATA VALIDATION
# =============================================================================

data_validation:
  stage: validate
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "ğŸ“Š Validating data quality..."
    - *dvc_setup
    - dvc pull -r ${DVC_REMOTE_NAME} || dvc pull || echo "âš ï¸ DVC pull failed (ensure remote configured)"

    - |
      python scripts/validate_data.py \
        --data ${DATA_PATH} \
        --suite california_housing_suite \
        --columns "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedHouseVal" \
        --column-types "MedInc:float64,HouseAge:float64,AveRooms:float64,AveBedrms:float64,Population:float64,AveOccup:float64,Latitude:float64,Longitude:float64,MedHouseVal:float64"

    - echo "âœ… Data validation complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

# =============================================================================
# STAGE 3: TRAIN CHALLENGER MODEL
# =============================================================================

train_challenger:
  stage: train
  image: continuumio/miniconda3:latest
  <<: *conda_setup
  script:
    - echo "ğŸš€ Training challenger model..."
    - *dvc_setup
    - dvc pull -r ${DVC_REMOTE_NAME} || dvc pull || echo "âš ï¸ DVC pull failed"

    # Train using DVC pipeline
    - dvc repro

    # Tag as challenger in MLflow
    - python scripts/tag_challenger.py --experiment-name ${EXPERIMENT_NAME} --tracking-uri ${MLFLOW_TRACKING_URI}

    - echo "âœ… Challenger model trained and tagged"
  artifacts:
    paths:
      - metrics.json
      - dvc.lock
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

# =============================================================================
# STAGE 4: EVALUATE & COMPARE MODELS
# =============================================================================

evaluate_models:
  stage: evaluate
  image: continuumio/miniconda3:latest
  needs: ["train_challenger"]
  <<: *conda_setup
  script:
    - echo "ğŸ“Š Comparing challenger vs champion..."

    # Compare models and generate decision
    - |
      python scripts/compare_models.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --tracking-uri ${MLFLOW_TRACKING_URI} \
        --metric ${PRIMARY_METRIC} \
        --improvement-threshold 0.01 \
        --output comparison.json

    # Generate CML report
    - |
      python scripts/generate_cml_report.py \
        --comparison comparison.json \
        --output report.md \
        --verbose

    # Post to MR using GitLab API directly (more reliable than CML)
    - |
      if [ -n "$CI_MERGE_REQUEST_IID" ] && [ -n "$GITLAB_API_TOKEN" ]; then
        echo "ğŸ“ Posting report to merge request..."

        # Install jq for JSON processing
        apt-get update -qq && apt-get install -y -qq jq curl

        # Escape markdown for JSON
        REPORT_BODY=$(jq -Rs . < report.md)

        # Post comment via GitLab API
        curl --request POST \
          --header "PRIVATE-TOKEN: ${GITLAB_API_TOKEN}" \
          --header "Content-Type: application/json" \
          --data "{\"body\": ${REPORT_BODY}}" \
          "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/merge_requests/${CI_MERGE_REQUEST_IID}/notes" \
          && echo "âœ… Report posted to MR" \
          || echo "âš ï¸ Failed to post report (check GITLAB_API_TOKEN)"
      else
        echo "â„¹ï¸ Not in MR context or GITLAB_API_TOKEN not set"
        echo "Report content:"
        cat report.md
      fi

    # Extract promotion decision for next jobs
    - |
      PROMOTE=$(python -c "
      import json
      with open('comparison.json') as f:
          data = json.load(f)
      print('yes' if data.get('promote_challenger', False) else 'no')
      ")
      echo "PROMOTE_MODEL=${PROMOTE}" >> promote.env

      echo "================================================"
      if [ "$PROMOTE" == "yes" ]; then
        echo "âœ… DECISION: Will promote challenger to champion"
      else
        echo "âš ï¸ DECISION: Keeping current champion"
      fi
      echo "================================================"
  artifacts:
    paths:
      - comparison.json
      - report.md
    reports:
      dotenv: promote.env
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

# =============================================================================
# MERGE DECISION GATE - Auto-merge control
# =============================================================================

merge_decision:
  stage: evaluate
  image: alpine:latest
  needs: ["evaluate_models"]
  before_script:
    - apk add --no-cache curl jq
  script:
    - echo "ğŸ” Evaluating merge eligibility..."
    - echo ""
    - |
      if [ "$PROMOTE_MODEL" == "yes" ]; then
        echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
        echo "â”‚  âœ… MODEL QUALITY GATE: PASSED              â”‚"
        echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
        echo "â”‚  â†’ Challenger outperforms champion          â”‚"
        echo "â”‚  â†’ Improvement threshold met                â”‚"
        echo "â”‚  â†’ Pipeline will succeed                    â”‚"
        echo "â”‚  â†’ Triggering auto-merge                    â”‚"
        echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
        echo ""

        # Auto-merge the MR using GitLab API
        if [ -n "$CI_MERGE_REQUEST_IID" ] && [ -n "$GITLAB_API_TOKEN" ]; then
          echo "ğŸ¤– Auto-merging MR !${CI_MERGE_REQUEST_IID}..."

          curl --request PUT \
            --header "PRIVATE-TOKEN: ${GITLAB_API_TOKEN}" \
            --url "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/merge_requests/${CI_MERGE_REQUEST_IID}/merge" \
            --data "should_remove_source_branch=true" \
            --data "merge_when_pipeline_succeeds=true" \
            --data "squash=false" \
            && echo "âœ… Auto-merge triggered" \
            || echo "âš ï¸ Auto-merge failed - check GITLAB_API_TOKEN permissions"
        else
          echo "âš ï¸ Cannot auto-merge: Missing CI_MERGE_REQUEST_IID or GITLAB_API_TOKEN"
        fi

        exit 0
      else
        echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
        echo "â”‚  âŒ MODEL QUALITY GATE: FAILED              â”‚"
        echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
        echo "â”‚  â†’ Challenger does not improve champion     â”‚"
        echo "â”‚  â†’ Improvement threshold not met            â”‚"
        echo "â”‚  â†’ Pipeline will fail                       â”‚"
        echo "â”‚  â†’ BLOCKING merge to protect quality        â”‚"
        echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
        echo ""
        echo "â„¹ï¸  Review comparison.json and report.md for details"
        exit 1
      fi
  allow_failure: false
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

# =============================================================================
# STAGE 5: PROMOTE MODEL (Only runs on main after merge)
# =============================================================================

promote_model:
  stage: evaluate
  image: continuumio/miniconda3:latest
  needs: []
  <<: *conda_setup
  script:
    - echo "ğŸ† Promoting challenger to champion..."
    - |
      python scripts/promote_model.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --tracking-uri ${MLFLOW_TRACKING_URI} \
        --output promotion_details.json
    - echo "âœ… Model promoted successfully"

    # Display promotion details
    - |
      if [ -f promotion_details.json ]; then
        echo "Promotion Details:"
        cat promotion_details.json
      fi
  artifacts:
    paths:
      - promotion_details.json
    expire_in: 30 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success

# =============================================================================
# STAGE 6: DEPLOY TO PRODUCTION (Only runs on main after promotion)
# =============================================================================

{% if deployment in ['ray-serve', 'all'] %}
build_docker:
  stage: deploy
  image: docker:24
  services:
    - docker:24-dind
  needs: ["promote_model"]
  before_script:
    - echo "ğŸ” Logging into Docker registry..."
    - docker login -u $DOCKER_HUB_USERNAME -p $DOCKER_HUB_TOKEN
  script:
    - echo "ğŸ³ Building Ray Serve deployment image..."

    # Build Docker image (Dockerfile.ray is in project root)
    - |
      docker build \
        -f Dockerfile.ray \
        -t ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        -t ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:latest \
        --build-arg MODEL_NAME=${MODEL_NAME} \
        --build-arg MODEL_VERSION=champion \
        .

    - echo "ğŸ§ª Testing built image..."
    - |
      # Start container in detached mode
      docker run -d --name test-serve \
        -e MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \
        -e MODEL_NAME=${MODEL_NAME} \
        -e MODEL_VERSION=champion \
        -e AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \
        -e AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \
        -e AWS_ENDPOINT_URL=${AWS_ENDPOINT_URL} \
        -e AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} \
        -e MLFLOW_S3_ENDPOINT_URL=${AWS_ENDPOINT_URL} \
        ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}

      # Wait for service to start
      echo "Waiting for service to start..."
      sleep 45

      # Check logs
      echo "Container logs:"
      docker logs test-serve

      # Health check
      echo "Running health check..."
      docker exec test-serve curl -f http://localhost:8000/health || {
        echo "âŒ Health check failed"
        echo "Full logs:"
        docker logs test-serve
        docker stop test-serve
        docker rm test-serve
        exit 1
      }

      # Cleanup
      docker stop test-serve
      docker rm test-serve
      echo "âœ… Image test passed"

    - echo "ğŸ“¤ Pushing images to registry..."
    - docker push ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:latest

    - echo "âœ… Docker images published successfully"
    - |
      echo "   SHA Image: ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    - |
      echo "   Latest: ${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:latest"

    # Save image info for deployment job
    - |
      echo "DOCKER_IMAGE=${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}" > docker_image.env
      echo "DOCKER_IMAGE_LATEST=${DOCKER_HUB_USERNAME}/${DOCKER_IMAGE_NAME}:latest" >> docker_image.env
  artifacts:
    reports:
      dotenv: docker_image.env
    paths:
      - docker_image.env
    expire_in: 7 days
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success

deploy_ray_serve:
  stage: deploy
  image: alpine:latest
  needs: ["build_docker"]
  before_script:
    - apk add --no-cache curl bash
  script:
    - echo "ğŸš€ Deploying to Ray Serve cluster..."
    - echo ""
    - echo "Deployment Configuration:"
    - |
      echo "  Image: ${DOCKER_IMAGE}"
    - |
      echo "  Model: ${MODEL_NAME}@champion"
    - |
      echo "  MLflow: ${MLFLOW_TRACKING_URI}"
    - |
      echo "  Environment: production"
    - echo ""

    - echo "ğŸ“ Production Deployment Steps:"
    - echo "  1. Connect to Ray cluster"
    - |
      echo "  2. Pull Docker image: ${DOCKER_IMAGE}"
    - echo "  3. Deploy via Ray Serve"
    - echo "  4. Verify health checks"
    - echo "  5. Update traffic routing"
    - echo ""

    # In production, this would execute actual deployment
    # Example with Ray Serve CLI:
    # serve deploy deployment_config.yaml
    # Or programmatically via Ray Serve API

    - echo "âœ… Deployment configuration validated"
    - echo "ğŸ’¡ Integrate with your Ray cluster for actual deployment"
    - echo ""
    - echo "To deploy manually:"
    - echo "  docker pull ${DOCKER_IMAGE}"
    - echo "  docker run -d -p 8000:8000 \\"
    - echo "    -e MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \\"
    - echo "    -e MODEL_NAME=${MODEL_NAME} \\"
    - echo "    -e MODEL_VERSION=champion \\"
    - echo "    ${DOCKER_IMAGE}"
  environment:
    name: production
    url: http://ray-serve.example.com
    deployment_tier: production
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      when: on_success

stop_deployment:
  stage: deploy
  image: alpine:latest
  needs: []
  script:
    - echo "ğŸ›‘ Stopping production deployment..."
    - echo "This would stop the Ray Serve deployment in production"
    - echo ""
    - echo "Steps:"
    - echo "  1. Drain existing connections"
    - echo "  2. Stop Ray Serve deployment"
    - echo "  3. Clean up resources"
    - echo ""
    - echo "âœ… Deployment stop procedure documented"
  when: manual
  environment:
    name: production
    action: stop
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
{% endif %}

# =============================================================================
# MANUAL OPERATIONS (Only on main branch)
# =============================================================================

rollback_model:
  stage: deploy
  image: continuumio/miniconda3:latest
  needs: []
  <<: *conda_setup
  script:
    - echo "âª Rolling back to previous champion..."
    - |
      python scripts/rollback_model.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --tracking-uri ${MLFLOW_TRACKING_URI}
    - echo "âœ… Rollback complete"
    - echo ""
    - echo "â„¹ï¸  Previous champion has been restored"
    - echo "ğŸ’¡ Verify in MLflow UI and redeploy if needed"
  when: manual
  allow_failure: false
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

sync_data_remote:
  stage: deploy
  image: continuumio/miniconda3:latest
  needs: []
  <<: *conda_setup
  script:
    - echo "â˜ï¸ Syncing data to remote storage..."
    - *dvc_setup
    - |
      dvc push -r ${DVC_REMOTE_NAME} && echo "âœ… Data synced successfully" || {
        echo "âŒ Data sync failed"
        echo "Ensure AWS credentials are configured:"
        echo "  - AWS_ACCESS_KEY_ID"
        echo "  - AWS_SECRET_ACCESS_KEY"
        echo "  - AWS_ENDPOINT_URL"
        echo "  - DVC_S3_BUCKET"
        exit 1
      }
  when: manual
  allow_failure: true
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

verify_deployment:
  stage: deploy
  image: alpine:latest
  needs: ["deploy_ray_serve"]
  before_script:
    - apk add --no-cache curl jq
  script:
    - echo "ğŸ” Verifying deployment health..."
    - echo ""
    - echo "This job would verify:"
    - echo "  1. Service is responding"
    - echo "  2. Model is loaded correctly"
    - echo "  3. Predictions are working"
    - echo "  4. Performance metrics are acceptable"
    - echo ""
    - echo "Example health check:"
    - echo "  curl http://ray-serve.example.com/health"
    - echo ""
    - echo "Example prediction test:"
    - echo "  curl -X POST http://ray-serve.example.com/predict \\"
    - |
      echo "    -H 'Content-Type: application/json' \\"
    - |
      echo "    -d '{\"features\": [[1.0, 2.0, 3.0]]}'"
    - echo ""
    - echo "âœ… Deployment verification steps documented"
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

force_promote:
  stage: deploy
  image: continuumio/miniconda3:latest
  needs: []
  <<: *conda_setup
  script:
    - echo "âš ï¸  FORCE PROMOTING MODEL (bypassing quality gate)"
    - echo ""
    - echo "This will promote the latest model regardless of performance."
    - echo "Use only in emergency situations!"
    - echo ""
    - |
      python scripts/promote_model.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --tracking-uri ${MLFLOW_TRACKING_URI} \
        --output force_promotion.json
    - echo ""
    - echo "âœ… Force promotion complete"
    - echo "âš ï¸  Remember to redeploy the service!"
  when: manual
  allow_failure: false
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# CLEANUP JOBS
# =============================================================================

cleanup_old_artifacts:
  stage: deploy
  image: alpine:latest
  needs: []
  script:
    - echo "ğŸ§¹ Cleanup old pipeline artifacts..."
    - echo "This job would clean up:"
    - echo "  - Old Docker images"
    - echo "  - Expired artifacts"
    - echo "  - Temporary files"
    - echo ""
    - echo "âœ… Cleanup documented"
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
