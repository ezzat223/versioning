# =============================================================================
# MLOps CI/CD Pipeline - GitLab
# =============================================================================
# Pipeline Philosophy:
# - Automation + Simplicity = Professionalism
# - Fast feedback loops
# - Fail fast on quality issues
# - Auto-promote models when they improve
# =============================================================================

variables:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://127.0.0.1:5001"
  DOCKER_IMAGE_NAME: "${PROJECT_NAME}-service" # Dynamically set
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  CONDA_PKGS_DIRS: "$CI_PROJECT_DIR/.cache/conda/pkgs"

  # Template Configuration - Update these for your project
  DATA_PATH: "data/processed/dataset.csv"
  EXPERIMENT_NAME: "${EXPERIMENT_NAME}"
  TARGET_COLUMN: "target"

# Define pipeline stages
stages:
- quality # Code quality & security
- validate # Data validation
- train # Train challenger model
- evaluate # Compare & decide
- deploy # Build & push Docker
- release # Tag & release

# Cache dependencies for faster builds
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
  - .cache/pip
  - .cache/conda
  - .venv/

# =============================================================================
# STAGE 1: CODE QUALITY & SECURITY
# =============================================================================

code_quality:
  stage: quality
  image: python:${PYTHON_VERSION}-slim
  before_script:
  - pip install --upgrade pip
  - pip install black flake8 mypy bandit safety
  script:
  # Code formatting check
  - echo "üé® Checking code formatting with Black..."
  - black --check src/ scripts/ || (echo "‚ùå Code not formatted. Run 'black src/ scripts/'" && exit 1)

  # Linting
  - echo "üîç Running flake8 linting..."
  - flake8 src/ scripts/ --max-line-length=100 --ignore=E203,W503 || true

  # Type checking
  - echo "üìù Running mypy type checking..."
  - mypy src/ scripts/ --ignore-missing-imports || true

  # Security scan
  - echo "üîí Running security checks..."
  - bandit -r src/ -ll || true
  - safety check --json || true

  - echo "‚úÖ Code quality checks completed"
  rules:
  - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
  - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 2: DATA VALIDATION
# =============================================================================

data_validation:
  stage: validate
  image: continuumio/miniconda3:latest
  before_script:
  - conda env create -f environment.yml -n mlops || conda env update -f environment.yml -n mlops
  - source activate mlops
  - pip install great-expectations
  script:
  - echo "üìä Validating data quality..."

  # Pull latest data from DVC
  - dvc pull || echo "‚ö†Ô∏è DVC pull failed, using local data"

  # Run data validation
  - python scripts/data_validation.py --data-path ${DATA_PATH}

  - echo "‚úÖ Data validation completed"
  artifacts:
    reports:
      junit: data_validation_report.xml
    paths:
    - data_validation_report.json
    expire_in: 30 days
  rules:
  - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
  - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 3: TRAIN CHALLENGER MODEL
# =============================================================================

train_challenger:
  stage: train
  image: continuumio/miniconda3:latest
  services:
  - name: mlflow/mlflow:latest
    alias: mlflow
  variables:
    MLFLOW_TRACKING_URI: "http://mlflow:5000"
  before_script:
  - conda env create -f environment.yml -n mlops || conda env update -f environment.yml -n mlops
  - source activate mlops
  script:
  - echo "üöÄ Training challenger model..."

  # Pull latest data
  - dvc pull

  # Train model with challenger tag
  - |
    python training/train.py \
      --data-path ${DATA_PATH} \
      --target-column ${TARGET_COLUMN} \
      --experiment-name ${EXPERIMENT_NAME}

  # Tag the run as challenger
  - python scripts/tag_challenger.py --experiment-name ${EXPERIMENT_NAME}

  - echo "‚úÖ Challenger model trained"
  artifacts:
    paths:
    - metrics.json
    - mlruns/
    expire_in: 30 days
  rules:
  - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
  - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 4: EVALUATE & COMPARE MODELS
# =============================================================================

evaluate_models:
  stage: evaluate
  image: continuumio/miniconda3:latest
  before_script:
  - conda env create -f environment.yml -n mlops || conda env update -f environment.yml -n mlops
  - source activate mlops
  - pip install cml
  script:
  - echo "üìä Comparing challenger vs champion..."

  # Compare models
  - python scripts/compare_models.py --experiment-name ${EXPERIMENT_NAME} --output comparison_report.json

  # Generate CML report
  - python scripts/generate_cml_report.py --comparison comparison_report.json --output cml_report.md

  # Post CML report to commit/MR
  - |
    if [ -f cml_report.md ]; then
      cml comment create cml_report.md
    fi

  # Decision: Auto-promote if challenger is better
  - |
    PROMOTE=$(python -c "
    import json
    with open('comparison_report.json', 'r') as f:
        report = json.load(f)
    print('yes' if report.get('promote_challenger', False) else 'no')
    ")

    if [ "$PROMOTE" == "yes" ]; then
      echo "‚úÖ Challenger outperforms champion - will promote"
      echo "PROMOTE_MODEL=true" >> promote.env
    else
      echo "‚ö†Ô∏è Challenger does not outperform champion - keeping current"
      echo "PROMOTE_MODEL=false" >> promote.env
    fi

  artifacts:
    paths:
    - comparison_report.json
    - cml_report.md
    reports:
      dotenv: promote.env
    expire_in: 30 days
  rules:
  - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
  - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 5: MODEL PROMOTION
# =============================================================================

promote_model:
  stage: evaluate
  image: continuumio/miniconda3:latest
  needs: [ "evaluate_models" ]
  before_script:
  - conda env create -f environment.yml -n mlops || conda env update -f environment.yml -n mlops
  - source activate mlops
  script:
  - echo "üèÜ Promoting challenger to champion..."

  # Promote model in MLflow
  - python scripts/promote_model.py --experiment-name ${EXPERIMENT_NAME}

  - echo "‚úÖ Model promoted successfully"
  rules:
  - if: '$PROMOTE_MODEL == "true"'

# =============================================================================
# STAGE 6: BUILD & PUSH DOCKER IMAGE (RAY SERVE)
# =============================================================================

build_ray_serve_image:
  stage: deploy
  image: docker:24
  services:
  - docker:24-dind
  needs: [ "promote_model" ]
  before_script:
  - docker login -u $DOCKER_HUB_USERNAME -p $DOCKER_HUB_TOKEN
  script:
  - echo "üê≥ Building Ray Serve Docker image..."

  # Build Ray Serve image
  - |
    docker build \
      -f deployment/Dockerfile.ray \
      --build-arg MODEL_NAME=${EXPERIMENT_NAME} \
      -t ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
      -t ${DOCKER_IMAGE_NAME}:latest \
      .

  # Push all tags
  - docker push ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
  - docker push ${DOCKER_IMAGE_NAME}:latest

  - echo "‚úÖ Ray Serve image pushed successfully"
  rules:
  - if: '$PROMOTE_MODEL == "true" && $CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 7: CREATE RELEASE
# =============================================================================

create_release:
  stage: release
  image: alpine:latest
  needs: [ "build_ray_serve_image" ]
  before_script:
  - apk add --no-cache git curl jq
  script:
  - echo "üè∑Ô∏è Creating release..."

  - export MODEL_VERSION="v1.0.${CI_PIPELINE_ID}"

  # Create git tag
  - git config user.email "ci@gitlab.com"
  - git config user.name "GitLab CI"
  - git tag -a ${MODEL_VERSION} -m "Release ${MODEL_VERSION} - Model promoted"
  - git push origin ${MODEL_VERSION} || echo "Tag already exists"

  - echo "‚úÖ Release created: ${MODEL_VERSION}"
  rules:
  - if: '$PROMOTE_MODEL == "true" && $CI_COMMIT_BRANCH == "main"'

# =============================================================================
# MANUAL JOBS (Optional)
# =============================================================================

# Manual rollback job
rollback_model:
  stage: deploy
  image: continuumio/miniconda3:latest
  before_script:
  - conda env create -f environment.yml -n mlops || conda env update -f environment.yml -n mlops
  - source activate mlops
  script:
  - echo "‚è™ Rolling back to previous champion..."
  - python scripts/rollback_model.py --experiment-name ${EXPERIMENT_NAME}
  - echo "‚úÖ Rollback completed"
  when: manual
  rules:
  - if: '$CI_COMMIT_BRANCH == "main"'
