# =============================================================================
# MLOps CI/CD Pipeline - SIMPLIFIED & EFFECTIVE
# =============================================================================

variables:
  PYTHON_VERSION: "3.11"
  MLFLOW_TRACKING_URI: "http://mlflow:5000"
  DOCKER_IMAGE_NAME: "{{ project_name }}-service"
  MODEL_NAME: "{{ project_name }}-model"
  EXPERIMENT_NAME: "{{ project_name }}-exp"
  DVC_REMOTE_NAME: "aws-store"
  DVC_S3_BUCKET: ""
  AWS_ENDPOINT_URL: ""
  CONDA_PKGS_DIRS: ".conda/pkgs"
  CONDA_ENVS_DIRS: ".conda/envs"

  # Project-specific (customize these)
  DATA_PATH: "data/processed/dataset.csv"
  TARGET_COLUMN: "target"
  {% if task_type == 'supervised' %}
  PRIMARY_METRIC: "test_accuracy"
  {% elif task_type == 'unsupervised' %}
  PRIMARY_METRIC: "test_reconstruction_error"
  {% else %}
  PRIMARY_METRIC: "test_accuracy"
  {% endif %}

stages:
  - quality
  - validate
  - train
  - evaluate
  - deploy

# Cache for faster builds
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - .cache/pip
    - .venv/
    - .conda/pkgs
    - .conda/envs

# =============================================================================
# STAGE 1: CODE QUALITY (Keep it simple!)
# =============================================================================

code_quality:
  stage: quality
  image: python:${PYTHON_VERSION}-slim
  before_script:
    - pip install black flake8 bandit safety
  script:
    # Formatting
    - echo "üé® Checking code formatting..."
    - |
      black --check src/ scripts/ || (echo "Run: black src/ scripts/" && exit 1)

    # Linting
    - echo "üîç Linting..."
    - flake8 src/ scripts/ --max-line-length=100 --ignore=E203,W503 || true

    # Security (just the essentials)
    - echo "üîí Security scan..."
    - bandit -r src/ scripts/ -ll || true
    - safety scan || true

    - echo "‚úÖ Code quality checks complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 2: DATA VALIDATION
# =============================================================================

data_validation:
  stage: validate
  image: continuumio/miniconda3:latest
  before_script:
    - apt-get update && apt-get install -y build-essential gcc
    - conda config --add channels conda-forge
    - conda install -n base -c conda-forge mamba -y
    - export CONDA_PKGS_DIRS="${CONDA_PKGS_DIRS}"
    - export CONDA_ENVS_DIRS="${CONDA_ENVS_DIRS}"
    - mamba env create -f environment.yml || mamba env update -f environment.yml --prune
    # Activate environment
    - source /opt/conda/etc/profile.d/conda.sh
    - conda activate {{ project_name }}
    # DVC remote setup
    - |
      if [ -n "$DVC_S3_BUCKET" ]; then
        dvc remote add -f ${DVC_REMOTE_NAME} s3://$DVC_S3_BUCKET
        [ -n "$AWS_ACCESS_KEY_ID" ] && dvc remote modify ${DVC_REMOTE_NAME} access_key_id $AWS_ACCESS_KEY_ID
        [ -n "$AWS_SECRET_ACCESS_KEY" ] && dvc remote modify ${DVC_REMOTE_NAME} secret_access_key $AWS_SECRET_ACCESS_KEY
        [ -n "$AWS_DEFAULT_REGION" ] && dvc remote modify ${DVC_REMOTE_NAME} region $AWS_DEFAULT_REGION
        [ -n "$AWS_ENDPOINT_URL" ] && dvc remote modify ${DVC_REMOTE_NAME} endpointurl $AWS_ENDPOINT_URL
        dvc remote default ${DVC_REMOTE_NAME}
      fi
  script:
    - echo "üìä Validating data quality..."
    - dvc pull -r ${DVC_REMOTE_NAME} || dvc pull || echo "‚ö†Ô∏è DVC pull failed (ensure cloud remote configured and seeded)"

    # Single validation script with Great Expectations
    - python scripts/validate_data.py \
      --data ${DATA_PATH} \
      --suite iris_suite \
      --columns "sepal length (cm),sepal width (cm),petal length (cm),petal width (cm),species" \
      --column-types "sepal length (cm):float64,sepal width (cm):float64,petal length (cm):float64,petal width (cm):float64,species:int64"

    - echo "‚úÖ Validation complete"
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 3: TRAIN CHALLENGER
# =============================================================================

train_challenger:
  stage: train
  image: continuumio/miniconda3:latest
  before_script:
    - apt-get update && apt-get install -y build-essential gcc
    - conda config --add channels conda-forge
    - conda install -n base -c conda-forge mamba -y
    - export CONDA_PKGS_DIRS="${CONDA_PKGS_DIRS}"
    - export CONDA_ENVS_DIRS="${CONDA_ENVS_DIRS}"
    - mamba env create -f environment.yml || mamba env update -f environment.yml --prune
    # Activate environment
    - source /opt/conda/etc/profile.d/conda.sh
    - conda activate {{ project_name }}
    - |
      if [ -n "$DVC_S3_BUCKET" ]; then
        conda run -n {{ project_name }} dvc remote add -f ${DVC_REMOTE_NAME} s3://$DVC_S3_BUCKET
        if [ -n "$AWS_ACCESS_KEY_ID" ]; then conda run -n {{ project_name }} dvc remote modify ${DVC_REMOTE_NAME} access_key_id $AWS_ACCESS_KEY_ID; fi
        if [ -n "$AWS_SECRET_ACCESS_KEY" ]; then conda run -n {{ project_name }} dvc remote modify ${DVC_REMOTE_NAME} secret_access_key $AWS_SECRET_ACCESS_KEY; fi
        if [ -n "$AWS_DEFAULT_REGION" ]; then conda run -n {{ project_name }} dvc remote modify ${DVC_REMOTE_NAME} region $AWS_DEFAULT_REGION; fi
        if [ -n "$AWS_ENDPOINT_URL" ]; then conda run -n {{ project_name }} dvc remote modify ${DVC_REMOTE_NAME} endpointurl $AWS_ENDPOINT_URL; fi
        conda run -n {{ project_name }} dvc remote default ${DVC_REMOTE_NAME}
      fi
  script:
    - echo "üöÄ Training challenger model..."
    - conda run -n {{ project_name }} dvc pull -r ${DVC_REMOTE_NAME} || conda run -n {{ project_name }} dvc pull

    # Train using DVC pipeline
    - conda run -n {{ project_name }} dvc repro

    # Tag as challenger
    - conda run -n {{ project_name }} python scripts/tag_challenger.py --experiment-name ${EXPERIMENT_NAME}

    - echo "‚úÖ Challenger trained"
  artifacts:
    paths:
      - metrics.json
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 4: COMPARE & DECIDE (with CML)
# =============================================================================

evaluate_models:
  stage: evaluate
  image: iterativeai/cml:0-dvc2-base1  # Official CML image
  needs: ["train_challenger"]
  before_script:
    - pip install --upgrade pip
    - pip install mlflow dvc
  script:
    - echo "üìä Comparing models..."

    # Compare challenger vs champion
    - |
      python scripts/compare_models.py \
        --experiment-name ${EXPERIMENT_NAME} \
        --metric ${PRIMARY_METRIC} \
        --improvement-threshold 0.01 \
        --output comparison.json

    # Generate markdown report using Python
    - |
      python scripts/generate_cml_report.py \
        --comparison comparison.json \
        --output report.md

    # Post report to MR using CML
    - |
      if [ "$CI_MERGE_REQUEST_IID" != "" ]; then
        cml comment create report.md
      else
        echo "Not in MR context, skipping CML comment"
        cat report.md
      fi

    # Decide on promotion
    - |
      PROMOTE=$(python -c "
      import json
      with open('comparison.json') as f:
          data = json.load(f)
      print('yes' if data.get('promote_challenger', False) else 'no')
      ")
      echo "PROMOTE_MODEL=${PROMOTE}" >> promote.env

      if [ "$PROMOTE" == "yes" ]; then
        echo "‚úÖ Will promote challenger"
      else
        echo "‚ö†Ô∏è Keeping current champion"
      fi
  artifacts:
    paths:
      - comparison.json
      - report.md
    reports:
      dotenv: promote.env
    expire_in: 30 days
  rules:
    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'
    - if: '$CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 5: PROMOTE (Only if better)
# =============================================================================

promote_model:
  stage: evaluate
  image: python:${PYTHON_VERSION}-slim
  needs: ["evaluate_models"]
  before_script:
    - pip install --upgrade pip
    - pip install mlflow
  script:
    - echo "üèÜ Promoting challenger to champion..."
    - python scripts/promote_model.py --experiment-name ${EXPERIMENT_NAME}
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'

# =============================================================================
# STAGE 6: DEPLOY (Only on main with promotion)
# =============================================================================

{% if deployment in ['ray-serve', 'all'] %}
build_docker:
  stage: deploy
  image: docker:24
  services:
    - docker:24-dind
  needs: ["promote_model"]
  script:
    - echo "üê≥ Building deployment image..."
    - docker login -u $DOCKER_HUB_USERNAME -p $DOCKER_HUB_TOKEN

    - |
      docker build \
        -f deployment/Dockerfile.ray \
        -t ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA} \
        -t ${DOCKER_IMAGE_NAME}:latest \
        .

    - docker push ${DOCKER_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    - docker push ${DOCKER_IMAGE_NAME}:latest

    - echo "‚úÖ Image pushed"
  rules:
    - if: '$PROMOTE_MODEL == "yes" && $CI_COMMIT_BRANCH == "main"'
{% endif %}

# =============================================================================
# MANUAL JOBS
# =============================================================================

rollback_model:
  stage: deploy
  image: python:${PYTHON_VERSION}-slim
  before_script:
    - pip install --upgrade pip
    - pip install mlflow
  script:
    - echo "‚è™ Rolling back to previous champion..."
    - python scripts/rollback_model.py --experiment-name ${EXPERIMENT_NAME}
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'

# Push data to remote (manual for cost control)
sync_data_remote:
  stage: deploy
  image: python:${PYTHON_VERSION}-slim
  before_script:
    - pip install --upgrade pip
    - pip install dvc dvc-s3
  script:
    - echo "‚òÅÔ∏è Syncing data to remote storage..."
    - dvc push -r aws-store || echo "Configure AWS credentials first"
  when: manual
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
