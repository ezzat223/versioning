# =============================================================================
# DATA CONFIGURATION (Common for all tasks)
# =============================================================================
data:
  path: "data/processed/iris.csv"
  test_size: 0.2
  validation_size: 0.1
  random_state: 42

# =============================================================================
# SUPERVISED LEARNING (Uncomment if using supervised template)
# =============================================================================
supervised:
  target_column: "target"
  model:
    type: "random_forest"
    n_estimators: 100
    max_depth: 10

# =============================================================================
# MLFLOW CONFIGURATION
# =============================================================================
mlflow:
  experiment_name: "iris-classification-4"
  model_name: "iris-classifier-4"
  tracking_uri: "http://localhost:5001"


# =============================================================================
# NOTES FOR DATA SCIENTISTS:
# =============================================================================
# This file is TRACKED by git, so:
# - Changes to these params will trigger DVC pipeline re-runs
# - Good for production/baseline configurations
# - For experiments, use MLflow Projects CLI overrides instead

# 1. PRODUCTION CONFIGS:
#    - Put baseline/production hyperparameters here
#    - These are tracked in git
#    - Changes trigger DVC pipeline re-runs
#
# 2. EXPERIMENTATION:
#    - Use MLflow Projects CLI to override params
#    - Example: mlflow run . -P learning_rate=0.01
#    - No git commits needed for experiments!
#
# 3. ACCESSING IN CODE:
#    - These params are passed as command-line arguments
#    - Configured in MLproject file
#    - Access via argparse in your training script
#
# 4. DVC INTEGRATION:
#    - Run: dvc repro
#    - DVC will re-run pipeline if params changed
#    - Automatic dependency tracking
