# =============================================================================
# Ray Serve Dockerfile - Production Ready with MLflow Integration
# =============================================================================

FROM rayproject/ray:2.9.0-py310

WORKDIR /app

# Copy and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ ./src/

# Build-time arguments (can be overridden)
ARG MODEL_NAME=model-name
ARG MODEL_VERSION=champion

# Runtime environment variables
ENV MODEL_NAME=${MODEL_NAME} \
    MODEL_VERSION=${MODEL_VERSION} \
    SERVE_MIN_REPLICAS=1 \
    SERVE_MAX_REPLICAS=4 \
    SERVE_TARGET_CONCURRENCY=8 \
    SERVE_NUM_CPUS_PER_REPLICA=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app

# Expose Ray Serve port
EXPOSE 8000

# Start Ray Serve
# MLFLOW_TRACKING_URI must be set at runtime via -e flag
CMD ["serve", "run", "src.deployment.ray_serve:entrypoint", "--host", "0.0.0.0", "--port", "8000"]
