# =============================================================================
# Ray Serve Dockerfile (Official Base Image)
# =============================================================================
# Use Official Ray Image
FROM rayproject/ray:2.9.0-py310

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY src/ ./src/

# Environment Variables
ENV MODEL_VERSION=latest \
    MODEL_NAME=model-name \
    MLFLOW_TRACKING_URI=http://127.0.0.1:5001 \
    PYTHONUNBUFFERED=1

# Expose Ray Serve Port
EXPOSE 8000

# Start Ray Serve
# This one is for real-time inference
# Replace ray_serve with ray_batch for batch inference
CMD ["serve", "run", "src.deployment.ray_serve:entrypoint"]
